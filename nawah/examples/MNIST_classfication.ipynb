{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d067846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Nawah\n",
    "import Nawah.nn as nn\n",
    "import Nawah.nn.functional as F\n",
    "import Nawah.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Nawah.data.Dataset):\n",
    "    def __init__(self, train=True, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        print(\"Fetching MNIST dataset...\")\n",
    "\n",
    "        mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "        print(\"Dataset fetched.\")\n",
    "\n",
    "        images = mnist.data\n",
    "        labels = mnist.target\n",
    "\n",
    "        images = images / 255.0\n",
    "\n",
    "        labels = labels.astype(int)\n",
    "        \n",
    "        images = images.astype(np.float32)\n",
    "\n",
    "        if train:\n",
    "            self.images = images[:60000]\n",
    "            self.labels = labels[:60000]\n",
    "        else:\n",
    "            self.images = images[60000:]\n",
    "            self.labels = labels[60000:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_flat = self.images[index]\n",
    "        \n",
    "        image_reshaped = image_flat.reshape(1, 28, 28)\n",
    "    \n",
    "        label = self.labels[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            image_reshaped = self.transform(image_reshaped)\n",
    "    \n",
    "        return image_reshaped, label\n",
    "    \n",
    "\n",
    "trainset = MNISTDataset()\n",
    "testset = MNISTDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5c3ca-bfa0-48cf-9d44-80b804fdfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = Nawah.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = Nawah.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d40fc5-30d4-42fd-96fd-155f6289a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetModernized(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=6)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "\n",
    "        flattened_size = 16 * 4 * 4\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_dim=flattened_size, out_dim=120)\n",
    "        self.fc2 = nn.Linear(in_dim=120, out_dim=84)\n",
    "        self.output_layer = nn.Linear(in_dim=84, out_dim=10)\n",
    "    \n",
    "    \n",
    "    @F.relu\n",
    "    def conv_block1(self, x):\n",
    "        return x >> self.conv1 >> self.bn1\n",
    "\n",
    "    @F.relu\n",
    "    def conv_block2(self, x):\n",
    "        return x >> self.conv2 >> self.bn2\n",
    "\n",
    "    @F.relu\n",
    "    def dense_block1(self, x):\n",
    "        return x >> self.fc1\n",
    "\n",
    "    @F.relu\n",
    "    def dense_block2(self, x):\n",
    "        return x >> self.fc2\n",
    "\n",
    "    def forward(self, x: Nawah.Tensor) -> Nawah.Tensor:\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        \n",
    "        \n",
    "        logits = (x >> self.conv_block1\n",
    "                    >> self.conv_block2\n",
    "                    >> F.flatten\n",
    "                    >> self.dense_block1\n",
    "                    >> self.dense_block2\n",
    "                    >> self.output_layer)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "model = LeNetModernized()\n",
    "print(\"Modernized LeNet model created successfully.\")\n",
    "print(\"Input to fc1 will have size:\", 16 * 4 * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45dc7d0-3ce7-4103-9936-ad14f57dd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitLoss(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8fe9d-d4a9-4275-982a-b114df1f658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels: Nawah.Tensor, num_classes=10):\n",
    "    labels_flat = labels.data.flatten()\n",
    "    \n",
    "    labels_int = labels_flat.astype(int)\n",
    "    \n",
    "    one_hot = np.zeros((labels_int.shape[0], num_classes))\n",
    "    one_hot[np.arange(labels_int.shape[0]), labels_int] = 1\n",
    "    \n",
    "    return Nawah.Tensor(one_hot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4cfc4-1ecd-4e4a-82bd-bc37693cd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nawah import Tensor\n",
    "\n",
    "criterion = nn.BCEWithLogitLoss(reduction=\"sum\") \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(\"--- Starting Training ---\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs) \n",
    "\n",
    "        one_hot_labels = to_one_hot(labels, num_classes=10)\n",
    "\n",
    "        loss = criterion(outputs, one_hot_labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data.item()\n",
    "        \n",
    "        predicted_probs = 1 / (1 + np.exp(-outputs.data))\n",
    "        predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "        \n",
    "        true_labels = labels.data.flatten()\n",
    "        \n",
    "        correct_predictions += (predicted_labels == true_labels).sum()\n",
    "        total_samples += len(true_labels)\n",
    "        \n",
    "        avg_loss = running_loss / total_samples\n",
    "        avg_acc = correct_predictions / total_samples\n",
    "        \n",
    "        progress_string = (\n",
    "            f\"Epoch {epoch + 1}/{EPOCHS} | \"\n",
    "            f\"Batch [{batch_idx + 1}/{len(trainloader)}] | \"\n",
    "            f\"Loss: {avg_loss:.4f} | \"\n",
    "            f\"Acc: {avg_acc:.2%}\"\n",
    "        )\n",
    "        print(progress_string + \"  \", end='\\r')\n",
    "\n",
    "    print()\n",
    "\n",
    "    final_epoch_loss = running_loss / total_samples\n",
    "    final_epoch_acc = correct_predictions / total_samples\n",
    "    print(f\"End of Epoch {epoch + 1} Summary | Average Loss: {final_epoch_loss:.4f} | Accuracy: {final_epoch_acc:.2%}\")\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f852ab0-0529-45ea-993f-9d22e48965d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CLASS_NAMES = [str(i) for i in range(10)]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"--- Making predictions on random test images ---\")\n",
    "\n",
    "num_images_to_show = 5\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    random_index = np.random.randint(0, len(testset))\n",
    "    \n",
    "    image_data, true_label_index = testset[random_index]\n",
    "    true_label_name = CLASS_NAMES[true_label_index]\n",
    "    \n",
    "    image_tensor = Nawah.Tensor(image_data)\n",
    "\n",
    "    input_tensor = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    output_logits = model(input_tensor)\n",
    "    \n",
    "    probabilities = 1 / (1 + np.exp(-output_logits.data))\n",
    "    predicted_index = np.argmax(probabilities)\n",
    "    predicted_name = CLASS_NAMES[predicted_index]\n",
    "    \n",
    "    image_to_display = image_data.squeeze()\n",
    "    \n",
    "    ax = plt.subplot(1, num_images_to_show, i + 1)\n",
    "    plt.imshow(image_to_display, cmap='gray')\n",
    "    \n",
    "    title_color = 'green' if predicted_name == true_label_name else 'red'\n",
    "    ax.set_title(f\"Predicted: {predicted_name}\\nTrue: {true_label_name}\", color=title_color)\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c89e0-76eb-4f10-a5e9-768a71b965c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85333140-ea73-4541-bbde-f4245674e2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
